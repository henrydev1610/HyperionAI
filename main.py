import os
import streamlit as st
from dotenv import load_dotenv
from langchain.chains import ConversationChain
from langchain.chains.conversation.memory import ConversationBufferMemory
from langchain.prompts import PromptTemplate
from langchain_groq import ChatGroq

load_dotenv()


groq_api_key = os.environ.get('GROQ_API_KEY')

if not groq_api_key:
    st.error("A vari√°vel de ambiente 'GROQ_API_KEY' n√£o est√° definida.")
    st.stop()

def main():
    st.title('Hyperion AI chat-bot ü§ñ')
    st.sidebar.title("Selecione uma LLM")     
    
    model = st.sidebar.selectbox(
        'Escolha um modelo',
        ['Mixtral-8x7b-32768', 'llama3-8b-8192']
    )
    
    conversation_memory_length = st.sidebar.slider('Tamanho da Resposta:', 1, 10, value=5)
    
    memory = ConversationBufferMemory(k=conversation_memory_length)
    
    # Caixa de texto para a pergunta do usu√°rio
    user_question = st.text_area('Fa√ßa uma pergunta...')
    
    # Bot√£o para enviar a pergunta
    if st.button('Pesquisar'):
        if user_question.strip() == "":
            st.warning("Por favor, insira uma pergunta antes de pesquisar.")
        else:
            # Inicializa o hist√≥rico do chat na sess√£o
            if 'chat_history' not in st.session_state:
                st.session_state.chat_history = []
            else:
                for message in st.session_state.chat_history:
                    memory.save_context({'input': message['human']}, {'output': message['AI']})
            
            # Inicializa o ChatGroq com a API key e o modelo selecionado
            groq_chat = ChatGroq(
                groq_api_key=groq_api_key,
                model_name=model
            )
            
            # Definir o template do prompt
            prompt_template = PromptTemplate(
                input_variables=["history", "input"],
                template="""
                Voc√™ √© um assistente de intelig√™ncia artificial que responde em Portugu√™s Brasileiro.
                Hist√≥rico de Conversa:
                {history}
                Pergunta do Usu√°rio:
                {input}
                Resposta em Portugu√™s Brasileiro:
                """
                            )
            
            # Configura a cadeia de conversa√ß√£o com a LLM, a mem√≥ria e o prompt personalizado
            conversation = ConversationChain(
                llm=groq_chat,
                memory=memory,
                prompt=prompt_template 
            )
            
            try:
                # Gera a resposta da LLM
                response = conversation.run(user_question)
                
                # Verifica se a resposta √© uma string ou um dicion√°rio
                if isinstance(response, dict) and 'response' in response:
                    resposta_texto = response['response']
                else:
                    resposta_texto = response  # Assume que response √© uma string
                
                # Adiciona a mensagem ao hist√≥rico
                message = {'human': user_question, 'AI': resposta_texto}
                st.session_state.chat_history.append(message)
                
                # Exibe a resposta do chatbot
                st.write('**Hyperion AI:**', resposta_texto)
            except Exception as e:
                st.error(f"Ocorreu um erro ao processar a sua pergunta: {e}")

if __name__ == '__main__':
    main()
